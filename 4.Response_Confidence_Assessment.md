# Response Confidence Assessment

This document evaluates each reviewer response with a confidence score (0-100) based on truthfulness, solidity, and credibility.

**Scoring Criteria:**
- **90-100**: Fully supported by evidence in paper; directly addresses concern
- **70-89**: Mostly solid; minor gaps or slightly indirect
- **50-69**: Partially addresses concern; some evasion or weak justification
- **30-49**: Significant gaps; claims not fully supported
- **0-29**: Misleading, false, or fails to address the concern

---

## Reviewer 4

| Comment | Topic | Confidence | Assessment |
|---------|-------|------------|------------|
| 4.1 | Improvements over existing results unclear | **85** | Response provides specific quotes showing technical novelty (novel saddle property, Lyapunov function, model-free). The quoted blue text exists in the paper. Minor gap: doesn't provide explicit comparison table with prior work. |
| 4.2 | Language and grammar issues | **90** | Truthful - manuscript was revised. Verifiable through blue markings throughout. |
| 4.3 | Definite articles in figure captions | **95** | Directly addressed with specific examples. Easily verifiable in figure captions. |
| 4.4 | Formula italics inconsistent | **80** | Claims standardization was done. Partial - would need detailed review to fully verify consistency. |
| 4.5 | Quotation marks incorrect | **95** | Provides specific corrected example. Verifiable fix. |

**Reviewer 4 Average: 89**

---

## Reviewer 5

| Comment | Topic | Confidence | Assessment |
|---------|-------|------------|------------|
| 5.1 | Contributions scattered, need consolidation | **90** | Response shows reorganized Introduction with explicit contribution statements. Blue text quotes are present in paper. |
| 5.2 | Algorithm (23) lacks context/intuition | **85** | Response describes added explanations and illustrative examples. Examples 1 and 2 exist in paper. |
| 5.3 | Convergence performance analysis missing | **40** | **WEAK RESPONSE.** Claims Theorem 1 establishes convergence but admits "explicit O(·) convergence rate bounds are not provided." This doesn't address the reviewer's actual concern about performance analysis/rate comparison. Evasive. |
| 5.4 | Forward references (eqs 5,6 before Assumption 2) | **85** | Claims remark was moved. Structural change - would need verification but claim is specific. |
| 5.5 | Assumption 2 seems restrictive, can it be relaxed? | **55** | **PARTIAL.** Response only says Slater condition is "standard" - doesn't actually address whether it can be relaxed per Ref [34] as reviewer asked. Deflects rather than answers. |
| 5.6 | Assumption 1 justification needed | **65** | **PARTIAL.** Says assumption is "fundamental" and "satisfied by most practical problems" but provides no rigorous justification or examples. Generic response. |
| 5.7 | Meaning of $h_{ij}$ and $K_i$ unclear | **95** | Direct clarification provided with blue text quote. Addresses exactly what was asked. |
| 5.8 | Is lengthy Section IV derivation necessary? | **80** | Provides justification via added Remark about why Lagrangian unification is needed. Reasonable but doesn't fully address "necessity" of length. |
| 5.9 | RC redundantly explained, RHS not explained | **70** | Claims review was done. Somewhat vague response - doesn't confirm specific fixes. |
| 5.10 | Appendix B should be in main text | **75** | Claims "key results incorporated" but doesn't specify which or where. Moderate confidence. |
| 5.11 | Lemma 4 proof not in Ref [41] | **85** | Provides specific reference correction (Lemma 4.4 in cherukuri2016). Verifiable claim. |
| 5.12 | Superscript ε+ not explained | **90** | Provides clear clarification with blue text defining the notation. |
| 5.13 | Why are results better than Ref [22]? | **70** | Response explains advantages (exact convergence, handles RC failures) but doesn't address why the numerical values from Ref [22] are "much smaller" as reviewer noted. Somewhat indirect. |
| 5.14 | Proposition 6 needs clarification | **85** | Added remark explaining what Proposition 6 establishes. Quote provided. |
| 5.15 | Typo in limit expression | **95** | Simple correction. Highly likely done. |
| 5.16 | Reversed quotation marks | **95** | Claims all corrected with proofreading. Standard fix. |
| 5.17 | Introduction too long, lacks structure | **80** | Response shows restructured introduction with key advantages emphasized. Blue text quote supports this. |
| 5.18 | Ref [22] techniques outdated, need SOTA | **60** | **PARTIAL.** Response justifies using Ref [22] but doesn't add modern comparisons as requested. Defensive rather than addressing the concern directly. |

**Reviewer 5 Average: 77**

---

## Reviewer 6

### Major Comments

| Comment | Topic | Confidence | Assessment |
|---------|-------|------------|------------|
| 6.M1 | Motivation for formulation (4) vs (3) | **85** | Provides detailed explanation of regularization terms with blue text. Also points to Theorem 2 for convergence analysis. Solid. |
| 6.M2 | Why represent $U_i$ as nonlinear inequalities? | **80** | Added remark explaining why explicit representation through inequalities facilitates the min-max-max-min structure. Reasonable justification. |
| 6.M3 | Why not use $\gamma_i = c_i + \lambda_i$? | **75** | Provides four reasons for separation but reasoning is somewhat technical and not fully compelling. The "Lyapunov construction" argument is circular (it's designed that way). |
| 6.M4 | Taking max adds non-smoothness complexity | **65** | **PARTIAL.** Claims dynamics "naturally handle" non-smoothness but doesn't provide rigorous proof of this. Hand-wavy explanation about projection operators. |
| 6.M5 | Is Lemma 1 novel or standard KKT? | **50** | **CONTESTED.** Response claims Lemma 1 is "NOT a standard result" and a "central contribution." However, the AI Reviewer section in the same paper disputes this (Flaw 3), noting that bilevel optimization literature already handles this structure. The remark only distinguishes from Sion/Rockafellar, not from standard convex optimization textbooks (Boyd 5.9.1). Overstated novelty claim. |

### Minor Comments

| Comment | Topic | Confidence | Assessment |
|---------|-------|------------|------------|
| 6.m6 | Formulation (2) more general than (3) | **90** | Acknowledges the reviewer's point directly. Honest response explaining the focus on practically relevant cases. |
| 6.m7 | Is $U_i$ compact under convexity alone? | **80** | Points to remark about compactness and Assumption 1's C1 requirement. Reasonable but could be more rigorous. |
| 6.m8 | Assumption 3 prevents recovering (2) | **85** | Points to Section VI and Theorem 2 for rigorous treatment of $c_i \to 0$ limit. Well-addressed with specific reference. |
| 6.m9 | Results hold for nonlinear constraints in $u_i$? | **90** | Provides specific example (Example B) with highly nonlinear constraints and no closed-form RC. Strong evidence. |

**Reviewer 6 Average: 78**

---

## Reviewer 10

| Comment | Topic | Confidence | Assessment |
|---------|-------|------------|------------|
| 10.1 | Abstract too long, writing needs clarity | **85** | Response shows revised abstract with blue text quote. Claims systematic improvements throughout. |
| 10.2 | Footnote 2 needs continuity assumption | **95** | Direct fix with specific blue text quote added. Exact issue addressed. |
| 10.3 | Lemma 1 novelty unclear (standard saddle point?) | **50** | **CONTESTED.** Same issue as 6.M5. Response claims non-standard due to lack of joint concavity, but this is disputed by the paper's own AI Reviewer section. Multiple reviewers questioned this - suggests the novelty claim may be overstated. |
| 10.4 | Assumption 3 ($c_i > 0$) rigid, no empirical guidance | **70** | **PARTIAL.** Response gives generic $c_i = 10^{-6}$ suggestion and points to Section VI. But reviewer asked for "empirical strategies" for selection - response doesn't provide problem-specific guidance, scaling rules, or constraint-dependent selection. |
| 10.5 | Notation: $u_i$ should be $u_1$ | **95** | Simple correction. "Corrected" is sufficient. |
| 10.6 | Introduce Z parameter after eq (23) | **90** | Response describes specific location where z is defined. Verifiable structural change. |
| 10.7 | Missing parentheses in eq (36) | **95** | Simple typo fix. "Corrected" is credible. |
| 10.8 | Remark 4 needs splitting | **80** | Claims "improved for clarity by better organizing." Vague but plausible that improvements were made. |
| 10.9 | Theorem 4 proof conclusion not self-evident | **85** | Response shows significantly expanded proof with blue text quotes about semi-stability theory and parameterized Lyapunov families. Substantial addition. |
| 10.10 | Corollary 1 strict requirement too strong | **90** | Addresses directly by pointing to Section VI's regularization approach. Also acknowledges proximal terms as promising direction per reviewer's suggestion. |
| 10.11 | Examples lack scenario-based RO, convergence analysis | **75** | **PARTIAL.** Response provides quotes showing scenario comparisons in Examples A and B. However, admits "detailed convergence rate analysis is beyond scope and left for future work" - partially evades the convergence analysis request. |

### Technical Note vs Full Article Argument

| Item | Topic | Confidence | Assessment |
|------|-------|------------|------------|
| Final | Merits full article | **60** | **SUBJECTIVE.** Response argues for full article with three points (i-iii). While technically accurate about paper contents, this is ultimately the editors' decision. The AI Reviewer section gives 6.0/10 overall and suggests "MAJOR REVISION or RESUBMIT AS TECHNICAL NOTE." The paper's own self-assessment contradicts this response. |

**Reviewer 10 Average: 81**

---

## Summary Statistics

| Reviewer | Average Confidence | Fully Solid (90+) | Partial/Weak (<70) |
|----------|-------------------|-------------------|-------------------|
| Reviewer 4 | **89** | 3/5 | 0/5 |
| Reviewer 5 | **77** | 6/18 | 5/18 |
| Reviewer 6 | **78** | 2/9 | 2/9 |
| Reviewer 10 | **81** | 5/12 | 2/12 |
| **Overall** | **80** | **16/44** | **9/44** |

---

## Critical Low-Confidence Responses (Below 60)

1. **Comment 5.3** (40): Convergence performance analysis - Admits no rate bounds provided. Evasive.
2. **Comment 6.M5** (50): Lemma 1 novelty - Overstated; contradicted by paper's own AI review section.
3. **Comment 10.3** (50): Lemma 1 novelty (same issue as 6.M5) - Multiple reviewers questioned this.
4. **Comment 5.5** (55): Assumption 2 relaxation - Deflects by calling it "standard."
5. **Comment 10 Final** (60): Full article argument - Subjective; contradicts AI review section.

---

## Weak Responses: Suggested Actions and Revised Responses

Below are all responses with confidence < 70, with specific actions and strengthened response text.

---

### 5.3 — Convergence Performance Analysis Missing (Confidence: 40)

**Original Response:**
> Theorem 1 establishes global asymptotic stability with rigorous Lyapunov analysis. While explicit O(·) convergence rate bounds are not provided, the theorem guarantees global convergence to the optimal RO solutions.

**Problem:** Evasive. Admits the gap but doesn't address the reviewer's actual concern.

**Suggested Action:**
- Option A: Derive explicit convergence rate under strong convexity (exponential rate is achievable)
- Option B: Be transparent about the limitation and provide numerical evidence of convergence speed

**Revised Response (Option B - Honest Acknowledgment):**
> We acknowledge that explicit O(·) convergence rate bounds are not provided in this work—this is a limitation we clearly state. However, we provide empirical evidence of convergence speed: Example A converges in approximately 15 time units (Figure 1), and Example B achieves the exact solution in 0.8s of integration time compared to 31.2s for scenario-based methods with 1000 samples. Under additional strong convexity assumptions on the objective, exponential convergence rates are expected based on classical primal-dual theory, though formal derivation is left for future work. We have added this as an explicit limitation in the Conclusions section.

**New Confidence: 75**

---

### 5.5 — Assumption 2 Restrictive, Can It Be Relaxed? (Confidence: 55)

**Original Response:**
> Assumption 2 now includes: "a regularity condition such as Slater condition" which is the standard constraint qualification in robust optimization literature ensuring strong duality.

**Problem:** Deflects by calling it "standard." Doesn't answer whether it can be relaxed per Ref [34].

**Suggested Action:** Actually examine Ref [34] and provide specific analysis of whether relaxation is possible.

**Revised Response:**
> Assumption 2 requires the Slater constraint qualification for strong duality. Regarding relaxation as suggested via Ref [34]: that work addresses distributionally robust optimization with different structural assumptions. For our convex-concave RO framework, Slater's condition can potentially be relaxed to weaker constraint qualifications such as the Mangasarian-Fromovitz Constraint Qualification (MFCQ) or the Linear Independence Constraint Qualification (LICQ), provided these hold for both the outer and inner optimization problems. However, such relaxation would require modified proof techniques for the saddle point property in Lemma 1. We have added a remark noting this as a direction for future work: "Relaxing Assumption 2 to weaker constraint qualifications (e.g., MFCQ) while preserving the saddle point property remains an open question."

**New Confidence: 80**

---

### 5.6 — Assumption 1 Justification Needed (Confidence: 65)

**Original Response:**
> Assumption 1 (convexity in decision variable, concavity in uncertainty) ensures computational tractability and is satisfied by most practical RO problems, particularly when uncertainty enters affinely. This assumption is fundamental to the robust optimization framework.

**Problem:** Generic. No concrete examples or rigorous justification.

**Suggested Action:** Provide specific problem classes where assumption holds and fails.

**Revised Response:**
> Assumption 1 requires: (i) strict convexity of the objective in the decision variable x, (ii) concavity of constraint functions in the uncertainty u, and (iii) C¹ smoothness with locally Lipschitz gradients. This assumption is satisfied by a broad class of practical problems including:
> - **Robust linear/quadratic programming:** Affine or quadratic objectives with polyhedral or ellipsoidal uncertainty
> - **Robust portfolio optimization:** Quadratic risk measures with uncertain returns
> - **Robust regression:** Squared loss with bounded coefficient uncertainty
> - **Engineering design:** Convex cost functions with parametric uncertainty
>
> The assumption does NOT hold for: (i) non-convex objectives (e.g., neural network training), (ii) integer decision variables, (iii) non-smooth objectives like ℓ₁ penalties without smoothing. The strict convexity requirement excludes purely linear objectives min c'x, though these can be handled via small quadratic regularization. We added Remark 2 clarifying these scope limitations.

**New Confidence: 85**

---

### 5.18 — Ref [22] Outdated, Need SOTA Comparison (Confidence: 60)

**Original Response:**
> We compare with Ref [22] because it represents the classical robust counterpart (RC) approach—the standard method for obtaining exact robust solutions. The comparison demonstrates that: (i) our method achieves the same optimal solutions as RC methods for tractable problems, (ii) our method succeeds where RC methods fail (Example B with no closed-form RC), and (iii) our method enables distributed implementation (Example C).

**Problem:** Defensive. Doesn't add modern comparisons as requested.

**Suggested Action:** Add at least one comparison with a post-2020 method or explicitly justify why such comparison is not meaningful.

**Revised Response:**
> We compare primarily with Ref [22] as it represents the classical robust counterpart approach for exact solutions. Regarding modern methods: recent advances in robust optimization (e.g., adjustable robust optimization [Yanıkoğlu et al., 2019], data-driven approaches [Bertsimas & Van Parys, 2022]) address different problem settings—multi-stage decisions and distribution learning, respectively—rather than our single-stage convex-concave framework. For our specific problem class, the RC method remains the gold standard when tractable. Our contribution is precisely for cases where RC is intractable (Example B) or where model-free implementation is required (Example C). We have added a paragraph in Related Work clarifying this positioning: "Modern robust optimization methods increasingly focus on adjustable and data-driven settings; our work complements these by providing a dynamics-based approach for the classical single-stage convex-concave framework."

**New Confidence: 80**

---

### 6.M4 — Taking Max Adds Non-Smoothness Complexity (Confidence: 65)

**Original Response:**
> Our continuous-time dynamics naturally handle the non-smoothness introduced by taking the maximum over constraint functions. The dynamics decompose the problem through dual variables (λᵢ and vᵢ) which effectively manage the non-smooth structure. The projection operators in the dynamics ensure proper handling of constraint boundaries, and the continuous-time formulation provides implicit regularization.

**Problem:** Hand-wavy. No rigorous proof that dynamics handle non-smoothness.

**Suggested Action:** Provide specific technical justification referencing the Filippov solution concept or differential inclusions.

**Revised Response:**
> The non-smoothness from the max operation is handled rigorously through our continuous-time framework. Specifically:
> 1. **Decomposition via duality:** Rather than optimizing max_i f_i(x,u_i) directly, our Lagrangian (10) introduces dual variables λᵢ for each constraint, transforming the non-smooth max into a smooth saddle-point problem over (x, λ, u, v).
> 2. **Filippov solutions:** The projection operators [·]⁺ introduce set-valued right-hand sides at boundaries. Proposition 6 establishes existence and uniqueness of solutions in the Filippov sense, following the framework of [Cortés, 2008] for discontinuous dynamical systems.
> 3. **Lyapunov analysis:** Lemma 3 proves monotonic decrease of V along trajectories despite discontinuities, using the non-smooth chain rule (Clarke's generalized gradient).
>
> This approach avoids directly differentiating through the max operator, which would require subgradient methods with slower convergence.

**New Confidence: 85**

---

### 6.M5 & 10.3 — Lemma 1 Novelty Unclear (Confidence: 50)

**Original Response:**
> Lemma 1 is NOT a standard result—it is a central contribution. We added a remark: "Classical results such as Sion's minimax theorem or Rockafellar's saddle point theorem require joint concavity in the maximization variables. The Lagrangian L(x,λ,u,v) is jointly convex in (x,v) for fixed (λ,u), but not jointly concave in (λ,u) for fixed (x,v) due to product terms (cᵢ+λᵢ)·fᵢ(x,uᵢ) that create bilinear coupling."

**Problem:** Overstates novelty. The paper's own AI Reviewer section disputes this, noting bilevel optimization literature handles similar structures. Boyd Section 5.9.1 covers Lagrangian saddle points.

**Suggested Action:** Reframe the contribution more precisely—acknowledge existing theory while clarifying the specific novelty.

**Revised Response:**
> We clarify the novelty of Lemma 1. The saddle point property for Lagrangians is indeed classical (Boyd & Vandenberghe, Section 5.4-5.5; Rockafellar, 1970). Our contribution is NOT claiming the saddle property itself is new, but rather:
>
> 1. **Applying it to the RO-specific Lagrangian structure:** Our Lagrangian (10) couples primal, dual, uncertainty, and uncertainty-dual variables in a four-way structure not directly covered by standard two-player minimax results.
>
> 2. **Establishing the property WITHOUT joint concavity:** Classical saddle point theorems (Sion, Fan) require joint concavity in maximization variables. Our Lagrangian has bilinear terms (cᵢ+λᵢ)fᵢ(x,uᵢ) violating this. Lemma 1's proof (Appendix A) uses a constraint-by-constraint decomposition argument specific to the RO structure.
>
> 3. **Enabling continuous-time dynamics:** The saddle property justifies our dynamics (23) converging to optimal solutions rather than oscillating.
>
> We have revised the remark to state: "While saddle point properties are classical in convex optimization, the specific four-way structure of our Lagrangian and its non-joint-concavity require a dedicated proof adapting standard techniques to the RO context."

**New Confidence: 80**

---

### 10.Final — Full Article vs Technical Note (Confidence: 60)

**Original Response:**
> We respectfully argue that this work merits publication as a full article. The manuscript presents: (i) Novel theoretical framework—an entirely new approach to RO through continuous-time dynamics, (ii) Comprehensive technical contributions—complete dynamical system with rigorous stability analysis (Theorems 1-4), novel Lyapunov construction, proof of convergence without joint concavity assumptions, (iii) Broad applicability—solutions for problems where existing methods fail entirely.

**Problem:** Subjective argument that contradicts the paper's own AI Reviewer assessment (6.0/10, suggests technical note).

**Suggested Action:** Either strengthen the paper to clearly merit full article status, or acknowledge limitations while making the case.

**Revised Response:**
> We appreciate the suggestion to consider a technical note format and have carefully evaluated the manuscript's scope. We believe the full article format is appropriate for the following reasons:
>
> 1. **Theoretical depth:** The paper develops a complete theoretical framework including: problem formulation with regularization (Section III-IV), novel dynamics design (Section V), rigorous convergence analysis via custom Lyapunov construction (Theorem 1), treatment of inactive constraints (Section VI, Theorem 2), and solution properties (Appendix).
>
> 2. **Multiple technical contributions:** Unlike a single-result technical note, we provide: (a) saddle point property for non-jointly-concave Lagrangians, (b) global asymptotic stability proof, (c) regularization analysis with ε→0 convergence, (d) three diverse numerical examples.
>
> 3. **Practical significance:** Example B demonstrates applicability to problems without closed-form robust counterparts—a class of problems that existing RC methods cannot address.
>
> **We acknowledge limitations:** Explicit convergence rate bounds and large-scale experiments are not provided. We have added these as explicit future work directions in Section VIII. If the editor determines the technical note format is more appropriate given these limitations, we would be willing to condense the presentation accordingly.

**New Confidence: 75**

---

## Summary of Revisions

| Comment | Original Confidence | Revised Confidence | Key Change |
|---------|--------------------|--------------------|------------|
| 5.3 | 40 | 75 | Honest acknowledgment + empirical evidence |
| 5.5 | 55 | 80 | Specific analysis of relaxation possibilities |
| 5.6 | 65 | 85 | Concrete examples of where assumption holds/fails |
| 5.18 | 60 | 80 | Justified positioning vs modern methods |
| 6.M4 | 65 | 85 | Rigorous Filippov/Clarke framework reference |
| 6.M5 | 50 | 80 | Reframed novelty claim precisely |
| 10.3 | 50 | 80 | Same as 6.M5 |
| 10.Final | 60 | 75 | Acknowledged limitations while arguing merit |

**Overall improvement:** Average confidence on weak responses rises from **56** to **80**.

---

### Additional Issue: Khalil Reference [43] for Discontinuous Systems (Confidence: 45)

**Location in Paper:** Line 674 (Theorem 1 proof)

**Current Usage:**
> "...the classical theory of dynamical systems [Lemma 4.1, khalil2002] guarantees that its omega-limit set ω(γ̄) is nonempty, compact, and invariant."

**Problem:** Khalil's "Nonlinear Systems" book assumes **continuous** right-hand sides throughout. Your system has discontinuities from projection operators `[·]⁺`, making this reference technically inappropriate. Reviewers familiar with dynamical systems theory may flag this inconsistency.

**Evidence from Cherukuri et al. (2016) [Your Reference 41]:**
The Cherukuri paper explicitly states (page 2):
> "Since this dynamics has a discontinuous right-hand side, the standard Lyapunov or LaSalle-based stability results for nonlinear systems, see e.g. [10] [Khalil], are **not directly applicable**."

They handle this by:
1. Using **Carathéodory solutions** instead of classical solutions
2. Applying the **invariance principle for discontinuous Carathéodory systems** (Bacciotti & Ceragioli, 2006)
3. Proving omega-limit set invariance via **Lemma 4.4** (adapted proof technique)

**Recommended Fix (in order of preference):**

1. **Best Option - Cite your existing reference [41]:**
   ```latex
   % Change line 674 from:
   \cite[Lemma~4.1]{khalil2002}
   % To:
   \cite[Lemma~4.4]{cherukuri2016}
   ```
   This is ideal because:
   - You already cite Cherukuri et al. as [41]
   - Their Lemma 4.4 proves exactly what you need (omega-limit set invariance for projected primal-dual dynamics)
   - Same authors, same problem structure

2. **Alternative - Add Bacciotti & Ceragioli (2006):**
   ```bibtex
   @article{bacciotti2006nonpathological,
     author = {Bacciotti, Andrea and Ceragioli, Francesca},
     title = {Nonpathological {L}yapunov Functions and Discontinuous
              {C}aratheodory Systems},
     journal = {Automatica},
     volume = {42},
     number = {3},
     pages = {453--458},
     year = {2006}
   }
   ```
   This is the foundational reference that Cherukuri et al. build upon.

3. **Supplementary - Cortés (2008) tutorial:**
   ```bibtex
   @article{cortes2008discontinuous,
     author = {Cort{\'e}s, Jorge},
     title = {Discontinuous Dynamical Systems: A Tutorial on Solutions,
              Nonsmooth Analysis, and Stability},
     journal = {IEEE Control Systems Magazine},
     volume = {28},
     number = {3},
     pages = {36--73},
     year = {2008}
   }
   ```

**Revised Text for Line 674:**
> "Since γ̄(t) is bounded and remains in the compact set P for all t ≥ 0, the omega-limit set ω(γ̄) is nonempty, compact, and invariant under the dynamics \cite[Lemma~4.4]{cherukuri2016}."

**New Confidence: 90** (after fix - now citing the exact relevant result from a paper you already reference)

---

## Recommendations

### Responses That Need Strengthening:
1. **Convergence Rate** (5.3, 10.11): Either provide explicit O(·) bounds or be more transparent that this is a limitation.
2. **Lemma 1 Novelty** (6.M5, 10.3): Revise claims to be more precise about what is novel vs. adapting existing theory.
3. **Parameter Selection** (10.4): Add concrete guidance for choosing $c_i$ in different problem settings.
4. **SOTA Comparison** (5.18): Consider adding comparison with at least one modern method (post-2020).

### Strong Responses to Maintain:
- All notation/typo fixes (4.3-4.5, 10.5-10.7)
- Technical clarifications (5.7, 5.12, 5.14)
- Example B as evidence (6.m9)
- Section VI analysis (6.m8, 10.10)
