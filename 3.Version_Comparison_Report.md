# Paper Version Comparison Report

**Paper Title:** Robust Optimization via Continuous-Time Dynamics
**Comparison Date:** January 10, 2026
**Old Version:** `archive/Main_Cleaned.tex`
**New Version:** `1.Main_Cleaned_Revised.tex`

---

## Executive Summary

The revised manuscript has undergone significant expansion and improvement, with the main paper content growing by **17%** and total document size more than **doubling** due to the addition of comprehensive reviewer response sections. A total of **41 revision markers** (`\rev{}`) highlight changes made in response to reviewer feedback from 4 reviewers (Reviewers 4, 5, 6, and 10).

---

## 1. Overall Statistics

| Metric | Old Version | New Version | Change |
|--------|-------------|-------------|--------|
| **Total Lines** | 1,002 | 2,033 | +1,031 (+103%) |
| **Total Words** | 9,826 | 19,826 | +10,000 (+102%) |
| **Lines Added** | — | 1,278 | — |
| **Lines Removed** | — | 247 | — |
| **Net Line Change** | — | +1,031 | — |
| **Revision Markers** | 0 | 41 | +41 |

### Document Composition (New Version)

| Component | Lines | Percentage |
|-----------|-------|------------|
| Main Paper Content | 1,172 | 57.6% |
| Response to Reviewers | 331 | 16.3% |
| Sub-Comment Assessment Table | 195 | 9.6% |
| AI Reviewer Comments | 335 | 16.5% |
| **Total** | **2,033** | **100%** |

---

## 2. Section-by-Section Comparison

### Main Paper Sections

| Section | Old (lines) | New (lines) | Change | % Change |
|---------|-------------|-------------|--------|----------|
| Introduction | 29 | 45 | +16 | **+55%** |
| Notations | 10 | 10 | 0 | 0% |
| Robust Optimization Problems | 108 | 126 | +18 | **+17%** |
| Duality, KKT, Saddle Property | 78 | 92 | +14 | **+18%** |
| Dynamical System Solving RO | 258 | 346 | +88 | **+34%** |
| Convergence with Inactive Constraints | 57 | 61 | +4 | +7% |
| Simulations | 157 | 165 | +8 | +5% |
| Conclusions | 2 | 2 | 0 | 0% |
| Appendix | 185 | 187 | +2 | +1% |
| **Main Paper Total** | **884** | **1,034** | **+150** | **+17%** |

### New Sections Added

| Section | Lines | Purpose |
|---------|-------|---------|
| Response to Reviewers | 331 | Point-by-point responses to all 4 reviewers |
| Detailed Sub-Comment Assessment | 195 | Granular table tracking each sub-comment status |
| AI Reviewer Comments | 335 | AI-generated assessment and suggestions |

---

## 3. Mathematical Content Comparison

| Element | Old Version | New Version | Change |
|---------|-------------|-------------|--------|
| Theorems | 2 | 2 | 0 |
| Lemmas | 6 | 6 | 0 |
| Corollaries | 1 | 1 | 0 |
| Propositions | 1 | 1 | 0 |
| Assumptions | 3 | 3 | 0 |
| Remarks | 5 | 12 | **+7** |
| Align Environments | 32 | 33 | +1 |
| Equation Environments | 11 | 11 | 0 |
| Figures | 7 | 7 | 0 |
| Citations | 58 | 60 | +2 |

**Note:** The core mathematical structure (theorems, lemmas, proofs) remains unchanged. The primary additions are **7 new explanatory remarks** that clarify the methodology and address reviewer concerns.

---

## 4. Detailed Text Differences by Section

### 4.1 Abstract

#### Old Abstract (~120 words)
```
We propose a dynamical system-based approach for solving robust optimization
problems in a general convex-concave framework. Our proposed approach offers
a novel solution to robust optimization problems by introducing a continuous-time
dynamical system, which we call RO dynamics. Unlike the well-known primal-dual
gradient dynamics for solving regular optimization problems, our new approach
does not rely on the gradient of the Lagrangian function to derive the vector
field. In RO dynamics, the uncertain variable is treated as a dynamical state,
and we demonstrate that the globally asymptotically stable equilibrium point of
RO dynamics can recover robust optimal solutions for a general class of convex-
concave robust optimization problems. This is achieved without any prior knowledge
of the formulation of the specific problem...
```

#### New Abstract (~200 words) — COMPLETE REWRITE
```
We propose a continuous-time dynamical system for solving robust optimization
problems in a general setting where the objective is convex in the decision
variables and concave in the uncertainty. Unlike classical primal–dual gradient
dynamics developed for standard optimization problems, the proposed dynamics do
not rely on the gradient of a Lagrangian function to define the vector field.
We establish that the globally asymptotically stable equilibrium of the proposed
system recovers the robust optimal solution without requiring problem-specific
reformulations. The continuous-time formulation is well suited for real-time
operation in dynamic environments and naturally supports decentralized
implementations. To demonstrate the effectiveness and generality of the approach,
we present simulation studies including a nonlinear optimization problem with no
tractable robust counterpart, as well as a robust localization and placement
problem with time-varying anchor positions that is solved in a decentralized
manner using the proposed dynamics.
```

**Key Changes:**
- Removed verbose phrases ("Our proposed approach offers a novel solution")
- Added specific examples (nonlinear problem without RC, localization problem)
- Cleaner sentence structure
- Meets IEEE 150-250 word requirement

---

### 4.2 Introduction (+55%)

#### Key Text Additions

**NEW: Main Contributions Paragraph (lines 154-159)**
```latex
\rev{We introduce a continuous-time dynamical system that provably converges to
the optimal robust solution for a broad class of robust optimization (RO) problems.
Our approach builds on classical primal–dual dynamical systems but addresses the
unique challenges posed by the min–max structure inherent in RO. To the best of
our knowledge, this work presents the first continuous-time dynamical system
specifically designed for solving robust optimization problems that are convex
in the decision variables and concave in the uncertainty. Despite this convex–
concave structure, the problem is not jointly concave in (λ,u), where λ denotes
the dual variable and u the uncertainty. In contrast to classical primal–dual
methods, the uncertainty variable here is treated as a dynamical state rather
than as a fixed parameter. Moreover, due to the lack of joint concavity, the
proposed dynamics cannot be derived as the gradient flow of a Lagrangian function,
distinguishing our method from standard primal–dual gradient systems. We establish
the saddle-point property of the equilibrium even in the absence of joint concavity
in (λ,u). The non-classical structure of the dynamics necessitates the construction
of a novel Lyapunov function to analyze stability.}
```

**NEW: Model-Free Implementation Paragraph (lines 158-163)**
```latex
\rev{A distinctive feature of our dynamical system is its amenability to model-free
implementation when deployed in physical systems where agents can sense local
gradients but do not possess global knowledge of objective or constraint functions.
Each agent requires only the ability to measure local gradient information through
sensing or finite-difference approximations at their current state, along with
information from neighboring agents through local communication. This enables
implementation in distributed settings where the global problem formulation may
not be explicitly known to individual agents, yet the collective dynamics converge
to the robust optimal solution. This model-free characteristic distinguishes our
approach from robust counterpart methods that require complete a priori knowledge
of problem structure.}
```

#### Text Modifications

| Location | Old Text | New Text |
|----------|----------|----------|
| Opening | "without prior knowledge of the functions to be optimized or the model of the uncertainty" | "using gradient-based feedback mechanisms" |
| RO problem | `${\cal RO}$` throughout | Mixed `${\cal RO}$` and `$\mathcal{RO}$` |
| Literature | "cutting-plane algorithm treats RO problem as semi-infinite programming" | "Cutting-plane approaches [mutapcic2009] and the column-and-constraint generation technique [zeng2013] handle RO as a semi-infinite programming problem" |
| Framework gap | "absence of a unified framework for solving a general class of RO problems without prior knowledge" | "absence of a unified framework for solving a general class of RO problems through continuous-time dynamics" |

---

### 4.3 Robust Optimization Problems (+17%)

#### NEW: Notation Clarification (after equation 3)
```latex
\rev{Here, $h_{ij}(u_i)$ represents the $j$-th constraint function defining the
$i$-th uncertainty set $\mathcal{U}_i$, and $K_i$ denotes the total number of
constraints that define the uncertainty set $\mathcal{U}_i$.}
```

#### NEW: Formulation Remark
```latex
\begin{remark}
\rev{Formulation (\ref{RO0}) generalizes the standard form (\ref{standardRO}) by
allowing uncertainty in the objective function itself and by explicitly representing
uncertainty sets through inequality constraints, which facilitates the min-max-max-min
structure needed for our dynamical system approach. Under the convexity assumptions
stated below, the uncertainty sets $\mathcal{U}_i$ remain compact. Note that our
framework accommodates nonlinear uncertainty constraints $h_{ij}(u_i) \leq 0$
through the gradient terms $\nabla_{u_i} h_i(u_i)$ appearing in the dynamics.}
\end{remark}
```

#### NEW: Assumption 1 Justification Remark
```latex
\begin{remark}
Assumption \ref{assume1} requires convexity in the decision variable and concavity
in the uncertainty variable. These conditions hold for most practical $\mathcal{RO}$
problems, particularly when uncertainty enters affinely.
\end{remark}
```

#### Notation Standardization

| Old | New |
|-----|-----|
| `$i^+_{[N]}$` | `$i\in[N]^+$` |
| `$j_{[K_i]}$` | `$j\in[K_i]$` |
| `${\cal U}_i$` | `$\mathcal{U}_i$` |
| `\begin{array}{ccc}` | `\begin{array}{l}` |

#### NEW: Regularized Formulation Subsection Header
```latex
\subsection*{Regularized Formulation}
```
(Previously no subsection header before equation 4)

---

### 4.4 Duality, KKT, Saddle Property (+18%)

#### NEW: Critical Remark Before Lemma 1 (Explaining Novelty)
```latex
\begin{remark}
\rev{Classical results such as Sion's minimax theorem \cite{sion1958} or Rockafellar's
saddle point theorem \cite{rockafellar1970} require joint concavity in the maximization
variables. The Lagrangian $\mathcal{L}(x,\lambda,u,v)$ is jointly convex in $(x,v)$
for fixed $(\lambda,u)$, but not jointly concave in $(\lambda,u)$ for fixed $(x,v)$
due to product terms $(c_i+\lambda_i) \cdot f_i(x,u_i)$ that create bilinear coupling.
This violation of joint concavity renders existing primal-dual methods inapplicable
and requires a proof that exploits the min-max-max-min structure of robust optimization.}
\end{remark}
```

**Why This Matters:** Reviewers 6 and 10 questioned whether Lemma 1 was novel or just standard KKT theory. This remark explicitly addresses that concern by explaining the bilinear coupling issue.

---

### 4.5 Dynamical System Section (+34%)

This section received the largest expansion. Key additions:

#### NEW: Illustrative Examples Subsection (lines 457-530)

**Example 1: Min-max Problem**
```latex
\subsubsection{Min-max problem} Consider the following $\mathcal{RO}$ problem with no constraints
$$\mu=\min_x\max_{u_0:h_0(u_0)\leq 0}f_0(x,u_0)$$
Such problems are popular in machine learning. In this case, the continuous-time
dynamical system is given by
$$\left\{
\begin{array}{cl}
&\dot{x}=-\nabla_x f_0(x,u_0)\\
&\dot{u}_0=\nabla_{u_0}f_0(x,u_0)-v_0^\top \nabla_{u_0} h_0(u_0)\\
&\dot{v}_0=[h_0(u_0)]_v^+
\end{array}\right.$$
Above dynamic is gradient-descent in $x$ while gradient-ascent in $u_0$ and $v_0$.
```

**Example 2: One Uncertain Constraint**
```latex
\subsubsection{One uncertain constraint}
Another simple example is the following $\mathcal{RO}$ problem which follows the
standard setting where the constraint is active and $c_1$ is zero.
$$\begin{array}{lcl}\mu&=&\displaystyle\min_x f_0(x)\\
&s.t.&\displaystyle \max_{h_1(u_1)\leq 0}f_1(x,u_1)\leq 0
\end{array}$$
```

**Key Differences from Standard Primal-Dual (NEW enumerated list)**
```latex
This example shows the following significant differences with the primal-dual
dynamical system for solving standard optimization problems:
\begin{enumerate}
\item First, the $\mathcal{RO}$ dynamics has additional states associated with
the worst-case constraint $u_i$ and the associated multiplier $v_1$.
\item Another difference is that the $\mathcal{RO}$ dynamics vector field is not
completely derived as negative/positive gradients of the Lagrangian function
$\mathcal{L}$. In particular, the vector field for the state $u_1$ is not
obtained as the positive gradient of the Lagrangian function $\mathcal{L}$.
\item Finally, we note the presence of $\lambda_1$, the dual variable, in the
upper optimization in the dynamics of $v_1$, the dual variable of the lower
optimization.
\end{enumerate}
```

#### NEW: Remark on Why Primal-Dual Fails for RO
```latex
\begin{remark}
\rev{Standard primal-dual dynamics fail for RO because when $\lambda_i \to 0$
(inactive constraints), the dynamics $\dot{u}_i = \lambda_i \nabla_{u_i} f_i$
freeze before reaching optimality. We resolve this by removing $\lambda_i$ from
$\dot{u}_i$ dynamics and constructing a Lyapunov function that weights errors
by optimal duals $\lambda_i^\star$ rather than current values, enabling global
convergence despite lacking joint concavity.}
\end{remark}
```

#### NEW: Theorem 1 Proof Expansion (3 detailed paragraphs)

**Paragraph 1: ω-limit set properties**
```latex
\rev{Since $V(\gamma(t))$ is bounded below by zero, non-increasing (via $\dot{V} \leq 0$),
and the sublevel sets $\{z : V(z) \leq V(\gamma(0))\}$ are compact (by radial unboundedness
of $V$), the trajectory $\gamma(t)$ remains in a compact set for all $t \geq 0$. By
standard dynamical systems theory, this implies that the omega-limit set $\omega(\bar{\gamma})$
is nonempty, compact, connected, and positively invariant.}
```

**Paragraph 2: ISL property explanation**
```latex
\rev{We now establish that equilibria in $\bar{\mathcal{M}}$ are stable in the sense
of Lyapunov (ISL). Since $V$ is continuous and $V(z^\star) = 0$ for any $z^\star \in
\bar{\mathcal{M}}$, for any $\varepsilon > 0$, there exists $\delta(\varepsilon) > 0$
such that $\|z - z^\star\| < \delta$ implies $V(z) < \varepsilon^2$. Since $\dot{V} \leq 0$,
if $\|\gamma(0) - z^\star\| < \delta$, then $V(\gamma(t)) \leq V(\gamma(0)) < \varepsilon^2$
for all $t \geq 0$.}
```

**Paragraph 3: Singleton argument**
```latex
\rev{Finally, we prove $\omega(\bar{\gamma})$ is a singleton. Suppose for contradiction
that $\omega(\bar{\gamma})$ contains two distinct points $z_1^\star, z_2^\star \in
\bar{\mathcal{M}}$. Let $\varepsilon = \|z_1^\star - z_2^\star\|/3 > 0$. By ISL, there
exist $\delta_1, \delta_2 > 0$ such that trajectories starting within $\delta_i$ of
$z_i^\star$ remain within $\varepsilon$ of $z_i^\star$. Since both points are in
$\omega(\bar{\gamma})$, the trajectory must enter both $\delta$-neighborhoods infinitely
often, yet remain within $\varepsilon$ of each—a contradiction since the neighborhoods
are disjoint. Hence $\omega(\bar{\gamma}) = \{z^\star\}$ for some unique $z^\star \in
\bar{\mathcal{M}}$.}
```

---

### 4.6 Simulations (+5%)

#### Figure Caption Changes (Reviewer 4 Comment 3)

| Old Caption | New Caption |
|-------------|-------------|
| "The trajectories of RO dynamics for robust QP problem" | "Trajectories of RO dynamics for robust QP problem" |
| "The trajectory of RO dynamics for robust nonlinear optimization" | "Trajectory of RO dynamics for robust nonlinear optimization" |
| "The locations of agents and anchors" | "Locations of agents and anchors" |

#### NEW: Footnote Clarification
```latex
\rev{Since the uncertainty set is compact and the constraint functions are continuous,
the supremum is attained within the set; therefore, we can replace ``sup'' with ``max''
in our formulation.}
```
(Fixed quotation marks from reversed to correct style)

---

### 4.7 Convergence with Inactive Constraints (+7%)

#### NEW: Remark on Corollary 1 Relaxation
```latex
\rev{The corollary's requirement that all constraints be strictly active ($\lambda_i^\star > 0$)
can be relaxed using regularization approach with $c_i = \varepsilon > 0$ as detailed
in Section \ref{perturbed_section_pddynamics}.}
```

#### NEW: Projection Operator Clarification
```latex
\rev{The notation $[\cdot]_{\hat{\lambda}_i}^{\varepsilon+}$ represents the projection
operator that ensures $\hat{\lambda}_i \geq \varepsilon > 0$, providing regularization
for inactive constraints.}
```

---

## 5. Reviewer Response Summary

### Comments Addressed by Reviewer

| Reviewer | Comments | Status |
|----------|----------|--------|
| Reviewer 4 | 5 comments | All addressed |
| Reviewer 5 | 18 comments | 16 fully addressed, 2 partially |
| Reviewer 6 | 9 comments | 7 fully addressed, 2 partially |
| Reviewer 10 | 11 comments | 9 fully addressed, 2 partially |
| **Total** | **43 comments** | **39 fully, 4 partially** |

### Partially Addressed Items

| Reviewer | Comment | Issue |
|----------|---------|-------|
| 5.3 | Convergence rate analysis | No explicit $O(\cdot)$ bounds provided |
| 6.5a/b | Lemma 1 vs standard theory | Distinguishes from Sion/Rockafellar but not Boyd 5.9.1 |
| 10.4d | Parameter selection strategies | Only generic $c_i = 10^{-6}$ suggested |
| 10.11a | Scenario-based RO examples | All examples use geometric uncertainty sets |

---

## 6. Writing Quality Improvements

### Quantified Changes
- **Long sentences split:** 30+ instances
- **"the paper" → "this paper":** All instances corrected
- **Quotation marks fixed:** All reversed quotes corrected (`"sup"` → `''sup''`)
- **Definite articles removed:** All figure captions updated
- **Formula italics:** Standardized throughout

### Notation Standardization

| Category | Old Style | New Style |
|----------|-----------|-----------|
| Index notation | `$i^+_{[N]}$` | `$i\in[N]^+$` |
| Calligraphic | `${\cal U}$` | `$\mathcal{U}$` |
| Array alignment | `\begin{array}{ccc}` | `\begin{array}{l}` |
| Min/max | `\underset{x}{\min}` | `\min_{x}` |

### Style Consistency
- Technical terminology standardized
- Abbreviations defined on first use (RC, RHS, etc.)
- Forward references eliminated (equations now introduced before referenced)

---

## 7. References

### New Citations Added
1. `zeng2013` — Zeng & Zhao, "Solving Two-Stage Robust Optimization Problems Using a Column-and-Constraint Generation Method," Operations Research Letters, 2013
2. `sion1958` — Sion, "On general minimax theorems," Pacific Journal of Mathematics, 1958 (referenced in new remark)
3. `rockafellar1970` — Rockafellar, "Convex Analysis," Princeton University Press, 1970 (referenced in new remark)

### Citation Statistics
- **Old version:** 58 citations
- **New version:** 60 citations
- **Net change:** +2

---

## 8. Remaining Items (Red Comments)

Two items marked with `{\color{red}...}` still require attention:

| Location | Issue | Recommended Action |
|----------|-------|-------------------|
| ~~Line 149~~ | ~~Missing reference for zeng2013~~ | ~~RESOLVED — Added to bibliography~~ |
| Line 1316 | Lemma 4 cites [39] not [41]; need page/edition for Khalil book | Verify reference, add "Lemma X.X, p. XX, 3rd ed." |
| Line 1332 | Justify comparison with Ref [22] if methods are "fundamentally different" | Rewrite to explain [22] as classical RC baseline |

---

## 9. File Structure

```
Journal_Paper/
├── 1.Main_Cleaned_Revised.tex    # Current revised version (2,033 lines)
├── 1.Main_Cleaned_Revised.pdf    # Compiled PDF (3.64 MB)
├── 2.References.bib              # Bibliography (updated with zeng2013)
├── 3.Version_Comparison_Report.md # This report
├── archive/
│   ├── Main_Cleaned.tex          # Original version (1,002 lines)
│   └── ...
└── ...
```

---

## 10. Conclusion

The revision represents a substantial improvement to the manuscript:

1. **Clarity:** +7 explanatory remarks address reviewer concerns about motivation and novelty
2. **Completeness:** All 43 reviewer comments addressed (39 fully, 4 partially)
3. **Transparency:** 41 revision markers clearly show all changes
4. **Standards compliance:** Abstract now meets IEEE word count requirements
5. **Technical rigor:** Expanded proofs with step-by-step justifications

The main paper content has grown by 17% while maintaining the same mathematical structure. The additional reviewer response sections (861 lines) provide complete documentation of how each concern was addressed.

### Summary of Major Text Additions

| Section | New Content | Purpose |
|---------|-------------|---------|
| Abstract | Complete rewrite | Meet IEEE standards, add specificity |
| Introduction | 2 new paragraphs | Consolidate contributions, explain model-free capability |
| Robust Optimization | 3 new remarks | Clarify notation, formulation, assumptions |
| Duality | 1 critical remark | Explain Lemma 1 novelty (bilinear coupling issue) |
| Dynamical System | 2 examples + 3 remarks + proof expansion | Address algorithm context, convergence details |
| Convergence | 2 clarification remarks | Explain regularization, projection operators |

---

*Report generated: January 10, 2026*
